# GangaFlow (Ongoing ğŸš§)

**Your AI-powered gateway to mastering Ganga effortlessly.**

GangaFlow combines the power of LLMs with a Django + Channels backend and a React frontend to provide an intuitive, split-pane interface for [Ganga](https://ganga.readthedocs.io/en/latest/) â€” CERN's job management framework. No more command memorisation â€” talk to GangaBot and get the job done.

---

## What is GangaFlow?

GangaFlow is a GUI + LLM assistant that:
- Translates natural-language instructions into Ganga Python commands.
- Runs those commands live in a real PTY shell streamed over WebSocket.
- Maintains full chat memory and persists sessions to a local SQLite database.
- Keeps the Ganga shell and GangaBot chat side-by-side in a single browser tab.

---

## Interface

| Left pane | Right pane |
|-----------|------------|
| **Ganga Shell** â€” real PTY terminal over WebSocket | **GangaBot** â€” LLM chat with Markdown rendering |

![Frontend Sketch](./docs/interface_mockup.jpeg)

---

## Tech Stack

| Layer | Technology |
|-------|------------|
| Frontend | React 18, Vite 5, react-markdown, lucide-react |
| Backend | Django 5.1, Django Channels 4, Daphne (ASGI) |
| Terminal | ptyprocess â€” real PTY shell over WebSocket |
| LLM | Blablador API Â· `GPT-OSS-120b` (Helmholtz) |
| DB | SQLite â€” `ChatSession` + `ChatMessage` models |

---

## Prerequisites

- **Python 3.12** (other 3.10+ versions likely work)
- **Node.js 18+** and npm
- A **Blablador API key** from [Helmholtz AAI](https://login.helmholtz.de/)

---

## Installation

### 1. Clone

```bash
git clone https://github.com/your-username/ganga-flow.git
cd ganga-flow
```

### 2. Python environment

```bash
python3 -m venv .venv
source .venv/bin/activate      # Windows: .venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Environment variables

Create a `.env` file in the project root (never commit this):

```dotenv
BLABLADOR_API_KEY=your_key_here
GANGABOT_MODEL=1 - GPT-OSS-120b - an open model released by OpenAI in August 2025
GANGABOT_SYSTEM_PROMPT=You are GangaBot, an expert assistant for the Ganga job management framework used at CERN. Help users write, submit, and debug Ganga jobs. Always provide working Python code examples.
```

### 4. Database migrations

```bash
python manage.py migrate
```

### 5. Frontend dependencies

```bash
cd frontend && npm install && cd ..
```

---

## Running

Two processes must run simultaneously â€” open two terminal tabs.

**Terminal 1 â€” Django/ASGI backend (port 8000)**

```bash
source .venv/bin/activate
.venv/bin/daphne -p 8000 ganga_backend.asgi:application
```

**Terminal 2 â€” React dev server (port 3000)**

```bash
cd frontend
npm run dev
```

Open **http://localhost:3000** in your browser. The **Ganga Shell** and **GangaBot** status pills in the navbar turn green once each service is reachable.

---

## Project Structure

```
ganga-flow/
â”œâ”€â”€ assistant/
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ client.py        # Blablador HTTP wrapper
â”‚   â”‚   â””â”€â”€ chat.py          # GangaBot class (stateful, history-aware)
â”‚   â”œâ”€â”€ consumers.py         # PTY WebSocket consumer
â”‚   â”œâ”€â”€ models.py            # ChatSession + ChatMessage
â”‚   â”œâ”€â”€ views.py             # /api/chat/ endpoints
â”‚   â””â”€â”€ routing.py           # ws/terminal/ URL
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/components/
â”‚       â”œâ”€â”€ Navbar.jsx        # Live status pills
â”‚       â”œâ”€â”€ Terminal.jsx      # PTY shell pane
â”‚       â””â”€â”€ Chat.jsx          # GangaBot chat pane
â”œâ”€â”€ ganga_backend/
â”‚   â”œâ”€â”€ asgi.py              # ProtocolTypeRouter (HTTP + WS)
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ urls.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .env                     # (create yourself, never commit)
```

---

## API Endpoints

| Method | URL | Description |
|--------|-----|-------------|
| `POST` | `/api/chat/` | Send a message; returns `{ reply, session_id }` |
| `GET`  | `/api/chat/<session_id>/history/` | Fetch full message history for a session |

---

## Future Plans

- Ganga job graph visualiser
- Fine-tuned local LLM option
- Multi-user login with role-based access
- Deployment to CERN cloud

---

## Contributing

Pull requests, feature suggestions, and bug reports are welcome!  
See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines.

---

Made with â¤ï¸ by Soumya Shaw
cd frontend && npm run dev